{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Artificial Intelligence - Supervised Learning lab Session Part b\n",
    "--\n",
    "At the end of this session, you will be able to : \n",
    "- Learn the basics of pytorch in this [tutorial](Pytorch_tutorial.ipynb) (this can be done in parallel that the previous step if you work by groups of two)\n",
    "- Apply supervised learning on PyRat datasets and traini a classifer to predict the next movement to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tqdm package is useful to visualize progress with long computations. \n",
    "# Install it using pip. \n",
    "import tqdm\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import inspect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch tutorial\n",
    "--\n",
    "Go [here](Pytorch_tutorial.ipynb) and perform the pytorch tutorial before moving to part 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing PyRat using Machine Learning by training a classifier to predict the next movement to play (or - Supervised Baseline for Pyrat Challenge)\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we now take a step further with respect to Lab_1a and try to predict the next movement to play given a maze configuration. We therefore need to generate a new training dataset (X=canvas, y=next movement) with pyrat games to train a model. In particular we will train a deep neural network. Note that you will have to define a model in pytorch, so you have to do the pytorch tutorial first. \n",
    "\n",
    "The canvas here represents the state of the game and it corresponds to the vector that will be used to train the classifier. As we want to predict a next move, the canvas is twice the size of the maze and is centered on the player, so that we create a translation invariance.\n",
    "\n",
    "Have a look at the file `generate_SL_dataset.py`. It generates a dataset (`SupervisedLearning_experience.pt`) for training a classifier to predict the next move given a game configuration. The canvas (state of the game) is generated by the function `build_state` and is stored in memory together with the corresponding action at each turn of the game. `build_state` outputs a one layer canvas, but you can define other layers to put more information on the play (e.g. the location of the opponent could be put in a second layer). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'exemples : 877\n",
      "torch.Size([13, 9])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "### Load the pyrat_dataset that was stored as a .pt file by the generate_SL_dataset.py script. \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "BATCH_SIZE=50\n",
    "N_EPOCHS=20\n",
    "\n",
    "## CELL TO BE COMPLETED ##\n",
    "SL_dataset = r\"C:\\Users\\Moi\\DCL\\Track\\Intro_IA\\introduction-to-ai\\session4\\lab\\SupervisedLearning_experience.pt\"\n",
    "data=torch.load(SL_dataset)\n",
    "\n",
    "#how many examples?\n",
    "# Nombre d'exemples dans l'ensemble de données\n",
    "num_examples = len(data)\n",
    "print(\"Nombre total d'exemples :\", num_examples)\n",
    "\n",
    "\n",
    "# an example of the canvas (corresponding to first game) is\n",
    "x = data[0][\"state\"]\n",
    "print(x.shape)\n",
    "# the corresponding label (one-hot encoded 'action') \n",
    "y = data[0][\"action\"]\n",
    "print(y)\n",
    "\n",
    "# maze and canvas size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch (data, batch=BATCH_SIZE):\n",
    "\n",
    "    \"\"\"\n",
    "        This function builds batches from the dataset to train the model on.\n",
    "        Each batch is a pair (data, target), where each element has batch size as first dimension.\n",
    "        In:\n",
    "            \n",
    "            * experience:       List of experience situations encountered across games.\n",
    "                \n",
    "        Out:\n",
    "            * data:    Batch of data.\n",
    "            * targets: Targets associated with the sampled data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get indices\n",
    "    batch_size = min(batch, len(data))\n",
    "    indices = random.sample(range(len(data)), batch_size)\n",
    "\n",
    "    # Create the batch\n",
    "    X = torch.zeros(batch_size, data[0][\"state\"].shape[0]*data[0][\"state\"].shape[1])\n",
    "    y = torch.zeros(batch_size,dtype=torch.int64)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        # Data is the sampled state\n",
    "        X[i] = torch.flatten(data[indices[i]][\"state\"])  # flatten canvas (input to model)   \n",
    "        y[i] = data[indices[i]][\"action\"]\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now you have to train a classifier using supervised learning and evaluate it's performance. \n",
    "### Let's try a neural network.\n",
    "\n",
    "## Split your data into x_train, x_test, y_train, y_test.\n",
    "\n",
    "n = int(len(data) * 80/100)  # number of examples in the train set\n",
    "train_data=data[:n]\n",
    "test_data=data[n:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a neural network with two hidden layers. In pytorch, this correspond to only adding two layers of type \"Linear\".\n",
    "## You need to make sure that the size of the input of the first layer correspond to the width of your X vector. \n",
    "\n",
    "## CELL TO BE COMPLETED ##\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)  # Deuxième couche cachée\n",
    "        self.fc3 = nn.Linear(256, 128)  # Troisième couche cachée\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # Activation ReLU pour la première couche\n",
    "        x = F.relu(self.fc2(x))  # Activation ReLU pour la deuxième couche\n",
    "        x = self.fc3(x)          # Pas d'activation pour la dernière couche\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate your model spefying the in_features (size of a \"flattened\" input)\n",
    "\n",
    "net=Net(train_data[0]['state'].shape[0]*train_data[0]['state'].shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL TO BE COMPLETED ##\n",
    "## Define a loss function and optimizer\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 3.981\n",
      "[2] loss: 1.463\n",
      "[3] loss: 1.098\n",
      "[4] loss: 0.757\n",
      "[5] loss: 0.473\n",
      "[6] loss: 0.362\n",
      "[7] loss: 0.246\n",
      "[8] loss: 0.232\n",
      "[9] loss: 0.194\n",
      "[10] loss: 0.154\n",
      "[11] loss: 0.178\n",
      "[12] loss: 0.148\n",
      "[13] loss: 0.093\n",
      "[14] loss: 0.084\n",
      "[15] loss: 0.088\n",
      "[16] loss: 0.079\n",
      "[17] loss: 0.066\n",
      "[18] loss: 0.057\n",
      "[19] loss: 0.046\n",
      "[20] loss: 0.041\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## CELL TO BE COMPLETED ##\n",
    "## Train the network\n",
    "n_batch=len(data)//BATCH_SIZE\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    running_loss = 0\n",
    "    # get the inputs\n",
    "    for b in range(n_batch):\n",
    "        inputs,labels = make_batch(train_data)\n",
    "        # ZERO THE PARAMETERs GRADIENT\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        # FORWARD + BACKWARD + OPTIMIZE\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss/n_batch ))\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of the network: 99 %\n",
      "Test accuracy of the network: 78 %\n"
     ]
    }
   ],
   "source": [
    "## Check performances\n",
    "## Training accuracy\n",
    "correct = 0\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs,labels = make_batch(train_data, batch=len(train_data))\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Training accuracy of the network: %d %%' % (100 * correct / len(train_data)))\n",
    "        \n",
    "## Test accuracy\n",
    "correct = 0\n",
    "total = len(test_data)\n",
    "with torch.no_grad():\n",
    "    inputs,labels = make_batch(test_data, batch=len(test_data))\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test accuracy of the network: %d %%' % (100 * correct / len(test_data)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory AI does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Save the weights\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAI/trained_model_weights.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:627\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    624\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    628\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:501\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:472\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory AI does not exist."
     ]
    }
   ],
   "source": [
    "## Save the weights\n",
    "\n",
    "torch.save(net.state_dict(), 'AI/trained_model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks on training a NN \n",
    "\n",
    "If the training accuracy is about 20%, it means the network predicts the result as good as chance (5 possible choices: North, South, East, West, Nothing).\n",
    "\n",
    "When you train a neural network, you have to analyze your results. If, after the training, your training accuracy is far from 100%, your network is underfitting (high bias). Try to train the network longer (more epochs, bigger/smaller learning rate, batch size). Or, define a bigger network (more hidden layers, bigger out_features).  If, your test accuracy is far from your training accuracy, your network is overfitting (high variance). Try to regularize your optimization (look at L2 regularization, weight decay, drop out, early stopping...).\n",
    "Try to use more data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test in PyRat\n",
    "\n",
    "Now, it's time to test if your AI is able to beat an opponent. Open the `supervised_pyrat_player.py` file, and update the `TRAINED_MODEL_PATH` constant to set the path to the classifier you want to use. Also modify/complete the code corresponding to the parts\n",
    "\n",
    "########\n",
    "#### TODO ####   \n",
    "########\n",
    "\n",
    "Then run the `supervised_player.py` with the following command, changing the needed parameters. Make sure you use the same settings (width/height/number of cheeeses) as during training:\n",
    "\n",
    "<br />`python supervised_pyrat_player.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How well does the trained classifier play against the greedy? \n",
    "\n",
    "Now it's up to you to explore other possibilities to make a better player. A few starting points: \n",
    "- Change the \"canvas\" to add more information, such as the position of the other player. \n",
    "- Find more clever strategies to cross validate training, in order to enable a better estimate of generalization\n",
    "- Work on simpler versions of the problem (smaller maze, less cheese, ..) , to develop a better understanding of learning.\n",
    "- Generate datasets using another algorithm than the greedy (eg, a variant that surely beats the greedy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyrat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lab_commons_path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[0;32m     10\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(lab_commons_path)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlab_commons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmake_2_player_matches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msimulations\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlab_commons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgreedy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgreedy_player\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlab_commons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrandom_player\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moi\\DCL\\Track\\Intro_IA\\introduction-to-ai\\session4\\lab\\..\\..\\lab_commons\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlab_commons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmake_2_player_matches\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlab_commons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moi\\DCL\\Track\\Intro_IA\\introduction-to-ai\\session4\\lab\\..\\..\\lab_commons\\make_2_player_matches.py:15\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    This script makes multiple games between two programs, and compares the obtained scores.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    It performs two analyses: a quick average analysis and a formal 1 sample T test.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#####################################################################################################################################################\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m###################################################################### IMPORTS ######################################################################\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#####################################################################################################################################################\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Import PyRat\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyrat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# External imports\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpyplot\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyrat'"
     ]
    }
   ],
   "source": [
    "## CELL TO BE COMPLETED ##\n",
    "# You can use the simulations.run_several_games function to test the performances of your trained model vs a greedy or a random player\n",
    "\n",
    "import sys     # These lines correct a bug occuring in Notebooks.\n",
    "sys.argv=['']  # It's not perfect, but it works.\n",
    "\n",
    "import os\n",
    "lab_commons_path = os.path.join(os.getcwd(), \"..\", \"..\")\n",
    "if lab_commons_path not in sys.path:\n",
    "    sys.path.append(lab_commons_path)\n",
    "\n",
    "import lab_commons.make_2_player_matches as simulations\n",
    "import lab_commons.AI.greedy as greedy_player\n",
    "import lab_commons.AI.random as random_player\n",
    "import supervised_pyrat_player\n",
    "\n",
    "program_1 = supervised_pyrat_player \n",
    "program_2 = greedy_player\n",
    "program_3 = random_player\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to specify the number of games to run and the maze size\n",
    "num_games = 10  # Number of games to run\n",
    "maze_size = 21  # Size of the maze (odd number)\n",
    "\n",
    "# Run games and collect results\n",
    "results = simulations.run_several_games(num_games, maze_size, program_1, program_2, program_3)\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
